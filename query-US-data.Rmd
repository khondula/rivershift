---
title: "Query NWIS and Water Quality Portal for time series"
output: 
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
  html_notebook: 
    toc: yes
    toc_depth: 2
author: 'Kelly Hondula'
editor_options: 
  chunk_output_type: console
---


```{r setup, include = FALSE}
library(knitr)
opts_chunk$set(message = FALSE, warning = FALSE, out.width = '75%', cache = TRUE)
```

This notebook goes through searching the NWIS and WQP for time series of N, P, and chl. 

```{r, message = FALSE}
# devtools::install_github("USGS-R/dataRetrieval")
library(dataRetrieval)
library(dplyr)
library(lubridate)
library(glue)
library(ggplot2)
library(purrr)
library(readr)
library(DT)
library(stringr)
library(kableExtra)
```

Overview of data https://owi.usgs.gov/R/dataRetrieval.html#3

# Create link to rivershift-data directory

Create variable for data directory to save some typing

```{r}
data_dir <- "/nfs/rivershift-data"
data_dir <- "~/rivershift/"
```


# Find Parameters Codes

There are 16,980 parameters, grouped into 16 categories and identified by unique 5 digit codes. Load the object `parameterCdFile` from the dataRetrieval package to browse them. 

```{r}
parameterCdFile <- dataRetrieval::parameterCdFile
unique(parameterCdFile$parameter_group_nm)
```

The column `parameter_nm` in the parameter code table contains longer descriptions. Use the `grep()` function to search the text in this column to find descriptions containing the word "phosphorus". 

## List of phosphorus codes

```{r}
phosCds_df <- parameterCdFile %>%
  filter(stringr::str_detect(parameter_nm, pattern = fixed('phosphorus', ignore_case = TRUE))) %>%
  filter(parameter_group_nm != "Information")

p_codes <- unique(phosCds_df$parameter_cd)
```


```{r, echo = FALSE, results='asis'}
DT::datatable(phosCds_df) 
```

## List of nitrogen codes

```{r}
nitCds_df <-  parameterCdFile %>%
  filter(stringr::str_detect(parameter_nm, pattern = fixed('nitrogen', ignore_case = TRUE))) %>%
  filter(!parameter_group_nm %in% c("Physical", "Inorganics, Major, Non-metals", "Stable Isotopes", "Toxicity"))
n_codes <- unique(nitCds_df$parameter_cd)
```


```{r, echo = FALSE, results='asis'}
DT::datatable(nitCds_df) 
```


## List of chl codes

```{r}
chlCds_df <- parameterCdFile %>%
  filter(stringr::str_detect(parameter_nm, pattern = fixed('chlorophyll', ignore_case = TRUE)))

chl_codes <- unique(chlCds_df$parameter_cd)
```

## List of chl codes with ug/L (water)
```{r}
chlCds_water_df <- parameterCdFile %>%
  filter(stringr::str_detect(parameter_nm, pattern = fixed('chlorophyll', ignore_case = TRUE))) %>%
  filter(stringr::str_detect(parameter_units, pattern = fixed('ug/l', ignore_case = TRUE)))

chl_codes <- unique(chlCds_water_df$parameter_cd)

```


```{r, echo = FALSE, results='asis'}
DT::datatable(chlCds_df) 
```

Make a vector of all codes, data frame with codes and the 3 categories, and separate vectors for querying subset of parameters at a time (for API limitations).

```{r}
npc_codes <- c(chl_codes, n_codes, p_codes)
npc_codes1 <- npc_codes[1:100] 
npc_codes2 <- npc_codes[101:200]
npc_codes3 <- npc_codes[201:length(npc_codes)]
npc_codes_df <- parameterCdFile %>% 
  filter(parameter_cd %in% npc_codes) %>%
  dplyr::select(parameter_cd, parameter_group_nm, parameter_nm, casrn, srsname, parameter_units) %>%
  mutate(category = case_when(parameter_cd %in% chl_codes ~ "chl",
                              parameter_cd %in% n_codes ~ "nitrogen",
                              parameter_cd %in% p_codes ~ "phosphorus"))
```

# NWIS water quality data

## Find Sites with at least 10 years of data for each parameter separately

> whatNWISdata

Only re-run this section code if a broader set of parameters is needed, otherwise skip to reading in results with chunk named `nwis_ts_x_parm`

There needs to be at least one "major" filter for searching NWIS data. Strategy is to go through all the states to get a table of what is available through NWIS, using the built in vector of state abbreviations (`state.abb`)

Define function to save a csv file based on a state and set of parameter codes. use a code for the file name

```{r}
save_10yr_ts_nwis <- function(state_abbrev, my_codes, my_codes_cat = "chl"){
  whatNWISdata(stateCd = state_abbrev,
  parameterCd = my_codes) %>% 
  mutate(date_range_interval = ymd(begin_date) %--% ymd(end_date),
         date_range_yrs = suppressMessages(as.period(date_range_interval))/years()) %>%
  dplyr::filter(date_range_yrs > 10) %>%
  arrange(rev(date_range_yrs)) %>%
  readr::write_csv(glue("{data_dir}/nwis_query_{my_codes_cat}-{state_abbrev}.csv")) # change path here to re-run
}
```

Use function to save file for each state and set of codes. 

```{r, eval = FALSE, cache=TRUE}
purrr::walk(state.abb, ~save_10yr_ts_nwis(state_abbrev = .x, 
                                     my_codes = chl_codes, 
                                     my_codes_cat = "chl"))

purrr::walk(state.abb, ~save_10yr_ts_nwis(state_abbrev = .x, 
                                     my_codes = p_codes, 
                                     my_codes_cat = "phos"))

# max 100 parameter codes so split up n codes
purrr::walk(state.abb, ~save_10yr_ts_nwis(state_abbrev = .x, 
                                     my_codes = n_codes[1:100], 
                                     my_codes_cat = "nitr1"))

purrr::walk(state.abb, ~save_10yr_ts_nwis(state_abbrev = .x, 
                                     my_codes = n_codes[101:length(n_codes)], 
                                     my_codes_cat = "nitr2"))
```

Read in all separate state files and combine, then Join with site codes information to convert parameter codes to names


```{r}
par_codes_for_join <- dplyr::select(parameterCdFile, parameter_cd, 
                                    parameter_nm, parameter_units)

nwis_chl_ts <- purrr::map_df(fs::dir_ls("local-data", regexp = "nwis.*chl"), ~readr::read_csv(.x, col_types = c("ccccddcccccc?c?c???c?DDn?n"))) %>%
  left_join(par_codes_for_join, by = c("parm_cd" = "parameter_cd"))

nwis_phos_ts <- purrr::map_df(fs::dir_ls("local-data", regexp = "nwis.*phos"), ~readr::read_csv(.x, col_types = c("ccccddcccccc?c?c???c?DDn?n"))) %>%
  left_join(par_codes_for_join, by = c("parm_cd" = "parameter_cd"))

nwis_nitr_ts <- purrr::map_df(fs::dir_ls("local-data", regexp = "nwis.*nitr"), ~readr::read_csv(.x, col_types = c("ccccddcccccc?c?c???c?DDn?n"))) %>%
  left_join(par_codes_for_join, by = c("parm_cd" = "parameter_cd"))

```

Save combined file 

```{r}
nwis_chl_ts %>% readr::write_csv(glue("{data_dir}/us-data/chl_nwis_all_10yr_ts.csv"))
nwis_phos_ts %>% readr::write_csv(glue("{data_dir}/us-data/phos_nwis_all_10yr_ts.csv"))
nwis_nitr_ts %>% readr::write_csv(glue("{data_dir}/us-data/nitr_nwis_all_10yr_ts.csv"))
```

Read in from saved files

```{r nwis_ts_x_parm}
#nwis_chl_ts <- readr::read_csv(glue("{data_dir}/us-data/chl_nwis_all_10yr_ts.csv"))
nwis_phos_ts <- readr::read_csv(glue("{data_dir}/us-data/phos_nwis_all_10yr_ts.csv")) %>%
  filter(ymd(begin_date)>"1980-01-01") 

nwis_nitr_ts <- readr::read_csv(glue("{data_dir}/us-data/nitr_nwis_all_10yr_ts.csv")) %>%
  filter(ymd(begin_date)>"1980-01-01") 
```

Read in from saved files and filter out periphyton sites
```{r}
nwis_chl_ts <- readr::read_csv(glue("{data_dir}/us-data/chl_nwis_all_10yr_ts.csv")) %>%
    filter(stringr::str_detect(parameter_units, pattern = fixed('ug/l', ignore_case = TRUE))) %>%
  filter(ymd(begin_date)>"1980-01-01") 
```


View table
```{r, include = FALSE}
kable(nwis_chl_ts) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

## Find sites that have P, N, and chl

Using site numbers

How many sites with both N and P?

12,579

```{r}
sites_NP <- nwis_nitr_ts %>% 
  filter(site_no %in% nwis_phos_ts$site_no) %>% 
  pull(site_no) %>% unique()
length(sites_NP)
```

How many sites with all 3? 

453 sites 
345 sites w/ chla phytoplankton

```{r}
sites_all3 <- nwis_nitr_ts %>% 
  filter(site_no %in% nwis_phos_ts$site_no) %>% 
  filter(site_no %in% nwis_chl_ts$site_no) %>%
  pull(site_no) %>% unique()

length(sites_all3)
```


Get information about sites and filter to just stream sites (ST) (116 sites)

```{r}
site_info <- dataRetrieval::readNWISsite(sites_all3)
site_info %>% group_by(site_tp_cd) %>% summarize(n_sitetype = n())
sites_all3_streams <- site_info %>% filter(site_tp_cd == "ST") %>% pull(site_no)
sites_all3_streams <- sites_all3_streams[-98]
#data.frame(site_no = sites_all3_streams) %>%
data.frame(site_no = sites_all3_streams) %>% #something wrong with site id 98
#write_csv(glue("{data_dir}/us-data/sites_all3_streams.csv"))
write_csv("sites_all3_streams.csv")
```

## Get summary data of N, P, chl parameters for a site

> readNWISqw

```{r read_nwis_qw}
##site_id <- sites_all3_streams[98] # for testing code in function
# 

get_nwis_site_data <- function(site_id){
    #data_dir <- "/nfs/rivershift-data/"
    data_dir <- "~/rivershift/"
    nwis_data_site <- purrr::map(list(npc_codes1, npc_codes2, npc_codes3),
                                 ~readNWISqw(siteNumbers = site_id,
                           parameterCd = .x)) %>%
    purrr::map(~mutate(.x, rpt_lev_va = as.character(rpt_lev_va))) %>%
    purrr::map(~mutate(.x, sample_dt = as.character(sample_dt))) %>%
    purrr::map(~mutate(.x, prep_set_no = as.character(prep_set_no))) %>%
    purrr::map(~mutate(.x, anl_set_no = as.character(anl_set_no))) %>% 

    bind_rows()


    readr::write_csv(nwis_data_site,
                   glue::glue("{data_dir}/us-data/nwis_site_data/nwis-data_{site_id}.csv"))

  nwis_data_site10yr <- nwis_data_site %>%
    group_by(parm_cd) %>%
    summarise(n_count = n(),
            min_datetime = as.Date(min(startDateTime)),
            max_datetime = as.Date(max(startDateTime)),
            min_year = lubridate::year(min(startDateTime)),
            max_year = lubridate::year(max(startDateTime))) %>%
  mutate(date_range_interval = ymd(min_datetime) %--% ymd(max_datetime),
         date_range_yrs = suppressMessages(as.period(date_range_interval))/years()) %>%
  left_join(npc_codes_df, by = c("parm_cd" = "parameter_cd")) %>%
  arrange(-n_count) %>%
    filter(date_range_yrs > 10) %>%
        mutate(site_no = site_id) %>%
  dplyr::select(-min_datetime, -max_datetime, -date_range_interval)

  readr::write_csv(nwis_data_site10yr,
                   glue::glue("{data_dir}/us-data/nwis_site_summaries/nwis-summary_{site_id}.csv"))

#   # return(nwis_data_site10yr)
}
```

Run function over all stream sites with all 3 parameters

```{r}
get_nwis_site_data(site_id = sites_all3_streams[1])
purrr::walk(sites_all3_streams, ~get_nwis_site_data(.x))

# for troubleshooting
#purrr::walk(sites_all3_streams[225:length(sites_all3_streams)], ~get_nwis_site_data(.x))
# grep("14206425", sites_all3_streams)
# sites_all3_streams[224] # for some reason no site data returned from site 14206440 
# read in all sites and save as one big table
# readr::write_csv(nwis_data_10yr_sums, "nwis_all3_10yr_summaries.csv")
```



# Water Quality Portal 

That was searching NWIS, which is USGS data. The water quality portal includes data from states, EPA, USDA, etc. Note details about differences here: https://owi.usgs.gov/R/dataRetrieval.html#23. 

> There's not a function in WQP that returns period of record information like we did above via NWIS dataâ€¦(that feature may be implemented in the future). The following function returns sites that have collected phosphorus data in Wisconsin. There's no way to know if that site has collected one sample, or thousands.

Need to use characteristic names for all of WQP which [only seem to be available](https://github.com/USGS-R/dataRetrieval/issues/417) here: https://www.waterqualitydata.us/Codes/Characteristicname?mimeType=xml

**MonitoringLocationIdentifier**: A designator used to describe the unique name, number, or code assigned to identify the monitoring location.

```{r}
save_10yr_ts_wqp <- function(state_abbrev, 
                             char_name = "Phosphorus",
                             my_codes_cat = "phos"){
  
  char_Data <- readWQPdata(statecode = state_abbrev,
                           CharacteristicName = char_name)

  if(!is.null(char_Data)){
  siteInfo <- attr(char_Data, "siteInfo")

  char_Summary <- char_Data %>%
    group_by(MonitoringLocationIdentifier, 
             CharacteristicName,
             ResultMeasure.MeasureUnitCode) %>%
    summarise(count=n(),
            begin_datetime = min(ActivityStartDateTime),
            end_datetime = max(ActivityStartDateTime),
            max = max(ResultMeasureValue, na.rm = TRUE)) %>%
    arrange(-count) %>%
    left_join(siteInfo, by = "MonitoringLocationIdentifier")

  char_Summary_10yrs <- char_Summary %>%
    mutate(begin_date = as.Date(begin_datetime),
         end_date = as.Date(end_datetime)) %>%
    mutate(date_range_interval = ymd(begin_date) %--% ymd(end_date),
         date_range_yrs = 
           suppressMessages(as.period(date_range_interval))/years()) %>%
    dplyr::filter(date_range_yrs > 10) %>%
    arrange(-date_range_yrs)
  
  readr::write_csv(char_Summary_10yrs, 
                 glue("data/wqp_query_{my_codes_cat}-{state_abbrev}.csv"))    
  }

                             }


```

Run function over states to save results of 10 year + time series from WQP. This may include duplicates of what is in NWIS?

```{r, eval = FALSE, cache=TRUE}

purrr::walk(state.abb, ~save_10yr_ts_wqp(state_abbrev = .x, 
                                     char_name = "Phosphorus", 
                                     my_codes_cat = "phos"
                                     ))

purrr::walk(state.abb, ~save_10yr_ts_wqp(state_abbrev = .x, 
                                     char_name = "Chlorophyll",  
                                     my_codes_cat = "chl"))

purrr::walk(state.abb, ~save_10yr_ts_wqp(state_abbrev = .x, 
                                     char_name = "Nitrogen", 
                                     my_codes_cat = "nitr"))

```

Read in groups of CSV files to save summary tables for all states for each parameter

```{r}

wqp_col_types <- cols("begin_date" = "D", 
                      "end_date" = "D", 
                      "hucCd" = "c",
                      "HUCEightDigitCode" = "c",
                      "VerticalAccuracyMeasure.MeasureValue" = "n",
                      "HorizontalAccuracyMeasure.MeasureValue" = "n",
                      "VerticalMeasure.MeasureValue" = "n",
                      "StateCode" = "i",
                      "CountyCode" = "c",
                      "ConstructionDateText" = "c",
                      "WellDepthMeasure.MeasureValue" = "c",
                      "WellHoleDepthMeasure.MeasureValue" = "c",
                      "count" = "n",
                      "begin_datetime" = "D",
                      "end_datetime" = "D",
                      "max" = "n",
                      "dec_lat_va" = "n",
                      "dec_lon_va" = "n",
                      "LatitudeMeasure" = "n",
                      "LongitudeMeasure" = "n",
                      "date_range_interval" = "c",
                      "date_range_yrs" = "n",
                      "DrainageAreaMeasure.MeasureValue" = "n",
                      "ContributingDrainageAreaMeasure.MeasureValue" = "n",
                      "SourceMapScaleNumeric" = "n")

wqp_phos_ts <- purrr::map_df(fs::dir_ls("local-data", regexp = "wqp.*phos"),
                              ~readr::read_csv(.x, col_types = wqp_col_types))

wqp_nitr_ts <- purrr::map_df(fs::dir_ls("local-data", regexp = "wqp.*nitr"),
                              ~readr::read_csv(.x, col_types = wqp_col_types))

wqp_chl_ts <- purrr::map_df(fs::dir_ls("local-data", regexp = "wqp.*chl"),
                              ~readr::read_csv(.x, col_types = wqp_col_types))

```

```{r}
wqp_phos_ts %>% readr::write_csv(glue("{data_dir}/us-data/phos_wqp_all_10yr_ts.csv"))
wqp_nitr_ts %>% readr::write_csv(glue("{data_dir}/us-data/nitr_wqp_all_10yr_ts.csv"))
wqp_chl_ts %>% readr::write_csv(glue("{data_dir}/us-data/chl_wqp_all_10yr_ts.csv"))
```

Read in

```{r}
wqp_phos_ts <- readr::read_csv(glue("{data_dir}/us-data/phos_wqp_all_10yr_ts.csv"))
wqp_nitr_ts <- readr::read_csv(glue("{data_dir}/us-data/nitr_wqp_all_10yr_ts.csv"))
wqp_chl_ts <- readr::read_csv(glue("{data_dir}/us-data/chl_wqp_all_10yr_ts.csv"))
```


